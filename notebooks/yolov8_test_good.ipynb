{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URCNQBJrh08p"
   },
   "source": [
    "## checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czGVjduti3zA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHK467cWh0m9",
    "outputId": "95fc82ed-4135-4fb9-bc10-6b9401e47a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['36.plant-fire.txt', '36.plant-fire.txt', '36.plant-fire.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/36.plant-fire.txt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "src_path = r\"/content/FS_Data/train/labels\"\n",
    "\n",
    "class_dict = {}\n",
    "\n",
    "label_names = []\n",
    "\n",
    "for file in os.listdir(src_path):\n",
    "    \n",
    "    content = open(os.path.join(src_path,file))\n",
    "    \n",
    "    content_list = content.readlines()\n",
    "    \n",
    "    \n",
    "    for i , item in enumerate(content_list):\n",
    "        \n",
    "        # class_dict[item.split()[0]] = class_dict.get(item.split()[0],0)+1\n",
    "        \n",
    "        if item.split()[0]=='2':\n",
    "            label_names.append(file)\n",
    "            \n",
    "\n",
    "\n",
    "print(label_names)\n",
    "shutil.move(os.path.join(src_path,label_names[0]),\"/content\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpMtAW82jZ3Q"
   },
   "outputs": [],
   "source": [
    "img_path = r\"/content/FS_Data/train/images\"\n",
    "\n",
    "labels_path = r\"/content/FS_Data/train/labels\"\n",
    "\n",
    "for img in os.listdir(img_path):\n",
    "    \n",
    "    # s.add(img.split('.')[-1])\n",
    "    \n",
    "    ext = img.split('.')[-1]\n",
    "    \n",
    "    ind = len(ext)*-1\n",
    "    ind -=1\n",
    "    \n",
    "    if img[:ind]+'.txt' not in os.listdir(labels_path):\n",
    "        shutil.move(os.path.join(img_path,img),\"/content\")\n",
    "        # print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n30EXKPFoBhL"
   },
   "outputs": [],
   "source": [
    "%cp -r /content/FS_data.zip /content/drive/MyDrive/fire_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rv0l-n7lmlea"
   },
   "outputs": [],
   "source": [
    "!zip  -r \"/content/FS_data.zip\"  \"/content/FS_Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4E3SwV8Hh3__"
   },
   "source": [
    "## start the model work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qt4n5mZWMb2i"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PO8X1S7cZtla"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9x_uMgv9bz-j"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhwkqS2ib-S-"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/drive/MyDrive/fire_data/FS_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJ312z-mpdlt"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/violence_v3_edited.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0h7wBGtK5VN",
    "outputId": "d77ee425-7e73-4f0d-bb09-fa4ceeecc384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting unrar\n",
      "  Downloading unrar-0.4-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: unrar\n",
      "Successfully installed unrar-0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install unrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtyeME98LdAM"
   },
   "outputs": [],
   "source": [
    "# !unrar x \"/content/drive/MyDrive/Violence_data/Violence_test2.rar\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8y2EAmZYpw4v"
   },
   "outputs": [],
   "source": [
    "model = YOLO('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQzECLVNp5Q-",
    "outputId": "0facea01-1653-4965-d47c-6ddf1e85f3e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.88 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=v.yaml, epochs=50, patience=50, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3786118  ultralytics.nn.modules.Detect                [18, [192, 384, 576]]         \n",
      "Model summary: 295 layers, 25866742 parameters, 25866726 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/violence2/labels... 4879 images, 727 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5606/5606 [00:02<00:00, 2413.40it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/violence2/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/violence2/labels.cache... 4879 images, 727 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5606/5606 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train2/labels.jpg... \n",
      "Image sizes 416 train, 416 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50      3.24G      1.484      1.695      1.597         17        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:48<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:18<00:00,  2.24it/s]\n",
      "                   all       5606       5739       0.74      0.697      0.764      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50      3.12G       1.39      1.296      1.511         19        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:37<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:12<00:00,  2.44it/s]\n",
      "                   all       5606       5739      0.749      0.653       0.75      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50      3.24G      1.474      1.408      1.592         21        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:30<00:00,  2.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:09<00:00,  2.52it/s]\n",
      "                   all       5606       5739      0.657      0.651      0.676      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/50       3.1G      1.575       1.56      1.668         17        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:32<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:10<00:00,  2.50it/s]\n",
      "                   all       5606       5739      0.703      0.607      0.679       0.34\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/50      3.12G      1.561      1.512      1.643         12        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:33<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:09<00:00,  2.53it/s]\n",
      "                   all       5606       5739      0.634      0.593      0.645       0.33\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/50      3.11G      1.528      1.451      1.631         12        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:33<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:09<00:00,  2.51it/s]\n",
      "                   all       5606       5739      0.699      0.631      0.699      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/50      3.12G      1.498      1.393      1.614         18        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:32<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:10<00:00,  2.49it/s]\n",
      "                   all       5606       5739      0.746      0.684      0.772      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/50      3.11G      1.462      1.344       1.59         11        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:33<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:10<00:00,  2.51it/s]\n",
      "                   all       5606       5739      0.751       0.71      0.787       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/50      3.11G      1.448      1.311      1.583         14        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:34<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:10<00:00,  2.50it/s]\n",
      "                   all       5606       5739      0.759      0.706      0.797      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/50       3.1G      1.411       1.26      1.554         14        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:34<00:00,  2.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:10<00:00,  2.48it/s]\n",
      "                   all       5606       5739      0.808      0.719      0.827      0.502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/50       3.1G      1.395      1.223      1.547         15        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:34<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:10<00:00,  2.48it/s]\n",
      "                   all       5606       5739      0.826      0.744       0.85      0.525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/50      3.11G      1.368       1.18      1.523         16        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:31<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:10<00:00,  2.50it/s]\n",
      "                   all       5606       5739      0.809      0.762      0.852      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/50      3.23G       1.35      1.156      1.508         14        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:33<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:10<00:00,  2.50it/s]\n",
      "                   all       5606       5739      0.827      0.767      0.866      0.535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/50      3.09G       1.34      1.133      1.495         11        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:30<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:11<00:00,  2.48it/s]\n",
      "                   all       5606       5739      0.827      0.788      0.875      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/50      3.09G      1.321        1.1      1.489         12        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:33<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:10<00:00,  2.49it/s]\n",
      "                   all       5606       5739      0.853      0.784      0.882      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/50      3.23G      1.304      1.082      1.483         16        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 351/351 [02:33<00:00,  2.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 176/176 [01:10<00:00,  2.51it/s]\n",
      "                   all       5606       5739      0.858      0.804      0.898      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/50      3.22G      1.279      1.052      1.468         37        416:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 144/351 [01:01<01:18,  2.63it/s]"
     ]
    }
   ],
   "source": [
    "model.train( data = \"v.yaml\" , epochs = 50 , imgsz = 416 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YdDFVHOTJkA4"
   },
   "outputs": [],
   "source": [
    "res = YOLO('TEST/Test_4_good_start/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "it4cCUbUJryn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading https:\\www.hollywoodreporter.com\\wp-content\\uploads\\2013\\08\\hr_fox_sports280_a_l.jpg to hr_fox_sports280_a_l.jpg...\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "  0%|                                                                                       | 0.00/223k [00:00<?, ?B/s]WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 223k/223k [00:00<00:00, 1.05MB/s]\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "image 1/1 F:\\Model\\hr_fox_sports280_a_l.jpg: 384x640 1 violence, 1647.9ms\n",
      "Speed: 2.0ms preprocess, 1647.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.yolo.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.yolo.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'violence'}\n",
       " orig_img: array([[[229, 235, 242],\n",
       "         [229, 235, 242],\n",
       "         [229, 235, 242],\n",
       "         ...,\n",
       "         [204, 213, 226],\n",
       "         [205, 214, 227],\n",
       "         [205, 214, 227]],\n",
       " \n",
       "        [[229, 235, 242],\n",
       "         [229, 235, 242],\n",
       "         [229, 235, 242],\n",
       "         ...,\n",
       "         [204, 213, 226],\n",
       "         [205, 214, 227],\n",
       "         [205, 214, 227]],\n",
       " \n",
       "        [[228, 234, 241],\n",
       "         [228, 234, 241],\n",
       "         [228, 234, 241],\n",
       "         ...,\n",
       "         [205, 214, 227],\n",
       "         [205, 214, 227],\n",
       "         [205, 214, 227]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[157,  95,   1],\n",
       "         [158,  96,   2],\n",
       "         [159,  97,   3],\n",
       "         ...,\n",
       "         [190, 118,  10],\n",
       "         [191, 119,  11],\n",
       "         [191, 119,  12]],\n",
       " \n",
       "        [[159,  95,   1],\n",
       "         [160,  96,   2],\n",
       "         [161,  97,   3],\n",
       "         ...,\n",
       "         [192, 122,   9],\n",
       "         [190, 120,   7],\n",
       "         [187, 117,   4]],\n",
       " \n",
       "        [[159,  95,   1],\n",
       "         [160,  96,   2],\n",
       "         [161,  97,   3],\n",
       "         ...,\n",
       "         [192, 122,   9],\n",
       "         [190, 120,   7],\n",
       "         [187, 117,   4]]], dtype=uint8)\n",
       " orig_shape: (730, 1296)\n",
       " path: 'F:\\\\Model\\\\hr_fox_sports280_a_l.jpg'\n",
       " probs: None\n",
       " speed: {'preprocess': 2.003908157348633, 'inference': 1647.8955745697021, 'postprocess': 1.9984245300292969}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n",
      "WARNING  Video stream unresponsive, please check your IP camera connection.\n"
     ]
    }
   ],
   "source": [
    "res.predict(source = \"https://www.hollywoodreporter.com/wp-content/uploads/2013/08/hr_fox_sports280_a_l.jpg\",save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNYkKXqNcJMK",
    "outputId": "393d73c8-839c-45ea-9313-6c29e9dd6a63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to yolov8s.pt...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:00<00:00, 58.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dr1JETTdcl5I"
   },
   "outputs": [],
   "source": [
    "# results = model.train(data  ='v.yaml', epochs = 50 , imgsz = 320 ,  name = 'fire_smoke_test_8s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4oTQUGZqc1Zd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
